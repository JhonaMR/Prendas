/**
 * Script de migraci√≥n de datos de clients desde SQLite a PostgreSQL
 * 
 * Este script:
 * 1. Lee datos de la tabla `clients` desde SQLite
 * 2. Transforma tipos de datos y mapea columnas
 * 3. Maneja valores NULL apropiadamente
 * 4. Inserta datos en PostgreSQL con el esquema corregido
 * 
 * Requirements: 1.4, 3.1, 3.2, 3.3
 */

// Cargar variables de entorno
require('dotenv').config({ path: require('path').join(__dirname, '../../.env') });

const { getDatabaseConnectionManager } = require('../config/DatabaseConnectionManager');
const { initDatabase, query, transaction } = require('../config/database');
const logger = require('../controllers/shared/logger');

// Configuraci√≥n de migraci√≥n
const MIGRATION_CONFIG = {
  batchSize: 100, // Tama√±o del lote para inserci√≥n
  maxRetries: 3,  // Intentos m√°ximos por lote
  retryDelay: 1000 // Retardo entre reintentos (ms)
};

/**
 * Transforma un registro de SQLite al formato de PostgreSQL
 */
function transformClientRecord(sqliteRecord) {
  // Mapeo de columnas y transformaci√≥n de tipos
  // Manejo case-insensitive para sellerId
  const sellerIdValue = sqliteRecord.sellerId !== undefined ? sqliteRecord.sellerId : 
                       sqliteRecord.sellerid !== undefined ? sqliteRecord.sellerid : 
                       null;
  
  return {
    id: sqliteRecord.id,
    name: sqliteRecord.name,
    nit: sqliteRecord.nit,
    address: sqliteRecord.address,
    city: sqliteRecord.city,
    seller_id: sellerIdValue, // Mapeo: sellerId/sellerid ‚Üí seller_id
    active: sqliteRecord.active === 1, // Transformaci√≥n: INTEGER ‚Üí BOOLEAN (1=true, 0=false)
    created_at: sqliteRecord.created_at,
    updated_at: new Date().toISOString() // Valor por defecto
  };
}

/**
 * Valida un registro transformado
 */
function validateTransformedRecord(record) {
  const errors = [];
  
  // Validaciones requeridas
  if (!record.id) {
    errors.push('id es requerido');
  }
  
  if (!record.name) {
    errors.push('name es requerido');
  }
  
  // Validar tipos
  if (typeof record.active !== 'boolean') {
    errors.push('active debe ser booleano');
  }
  
  // Validar longitud m√°xima (prevenci√≥n de errores)
  if (record.id && record.id.length > 255) {
    errors.push('id excede longitud m√°xima (255)');
  }
  
  if (record.name && record.name.length > 255) {
    errors.push('name excede longitud m√°xima (255)');
  }
  
  if (record.nit && record.nit.length > 50) {
    errors.push('nit excede longitud m√°xima (50)');
  }
  
  if (record.city && record.city.length > 100) {
    errors.push('city excede longitud m√°xima (100)');
  }
  
  if (record.seller_id && record.seller_id.length > 255) {
    errors.push('seller_id excede longitud m√°xima (255)');
  }
  
  return {
    isValid: errors.length === 0,
    errors
  };
}

/**
 * Lee todos los registros de clients desde SQLite
 */
async function readSqliteClients() {
  logger.info('üìñ Leyendo datos de clients desde SQLite...');
  
  try {
    const dbManager = getDatabaseConnectionManager();
    const db = dbManager.getConnection();
    
    // Verificar que la tabla existe
    const tableExists = db.prepare(`
      SELECT name FROM sqlite_master 
      WHERE type='table' AND name='clients'
    `).get();
    
    if (!tableExists) {
      throw new Error('La tabla clients no existe en SQLite');
    }
    
    // Obtener conteo total
    const countResult = db.prepare('SELECT COUNT(*) as count FROM clients').get();
    const totalRecords = countResult.count;
    logger.info(`üìä Total de registros en SQLite: ${totalRecords}`);
    
    // Leer todos los registros
    const sqliteRecords = db.prepare('SELECT * FROM clients').all();
    
    logger.info(`‚úÖ ${sqliteRecords.length} registros le√≠dos de SQLite`);
    return sqliteRecords;
    
  } catch (error) {
    logger.error('‚ùå Error leyendo datos de SQLite:', error);
    throw error;
  }
}

/**
 * Inserta un lote de registros en PostgreSQL
 */
async function insertBatchToPostgres(batch, batchNumber) {
  const client = await require('../config/postgres').getPool().connect();
  
  try {
    logger.debug(`üìù Insertando lote ${batchNumber} (${batch.length} registros)...`);
    
    // Construir query de inserci√≥n masiva
    const columns = ['id', 'name', 'nit', 'address', 'city', 'seller_id', 'active', 'created_at', 'updated_at'];
    const placeholders = batch.map((_, rowIndex) => 
      `(${columns.map((_, colIndex) => `$${rowIndex * columns.length + colIndex + 1}`).join(', ')})`
    ).join(', ');
    
    const values = batch.flatMap(record => [
      record.id,
      record.name,
      record.nit,
      record.address,
      record.city,
      record.seller_id,
      record.active,
      record.created_at,
      record.updated_at
    ]);
    
    const sql = `
      INSERT INTO clients (${columns.join(', ')})
      VALUES ${placeholders}
      ON CONFLICT (id) DO UPDATE SET
        name = EXCLUDED.name,
        nit = EXCLUDED.nit,
        address = EXCLUDED.address,
        city = EXCLUDED.city,
        seller_id = EXCLUDED.seller_id,
        active = EXCLUDED.active,
        updated_at = EXCLUDED.updated_at
    `;
    
    await client.query(sql, values);
    
    logger.debug(`‚úÖ Lote ${batchNumber} insertado exitosamente`);
    return batch.length;
    
  } catch (error) {
    logger.error(`‚ùå Error insertando lote ${batchNumber}:`, error);
    throw error;
  } finally {
    client.release();
  }
}

/**
 * Valida que la migraci√≥n fue exitosa
 */
async function validateMigration() {
  logger.info('üîç Validando migraci√≥n...');
  
  try {
    // Usar el nuevo MigrationValidator para validaci√≥n completa
    const { MigrationValidator } = require('./validateMigration');
    const validator = new MigrationValidator();
    
    const validationResults = await validator.validateAll();
    
    if (!validationResults.passed) {
      const errorMessages = validationResults.errors.join(', ');
      throw new Error(`Validaci√≥n fall√≥: ${errorMessages}`);
    }
    
    logger.info('‚úÖ Validaci√≥n completada exitosamente');
    return {
      success: true,
      sqliteCount: validationResults.details.recordCounts?.details?.sqliteCount || 0,
      pgCount: validationResults.details.recordCounts?.details?.postgresCount || 0,
      matches: validationResults.details.recordCounts?.details?.match || false,
      validationResults: validationResults
    };
    
  } catch (error) {
    logger.error('‚ùå Error en validaci√≥n:', error);
    throw error;
  }
}

/**
 * Prepara el esquema de PostgreSQL para la migraci√≥n
 * Asegura que la tabla tenga la estructura correcta
 */
async function preparePostgresSchema() {
  logger.info('üîß Preparando esquema de PostgreSQL...');
  
  try {
    // 1. Verificar si la tabla existe
    const tableExists = await query(`
      SELECT EXISTS (
        SELECT FROM information_schema.tables 
        WHERE table_schema = 'public' 
        AND table_name = 'clients'
      );
    `);
    
    if (!tableExists.rows[0].exists) {
      logger.info('üìã Creando tabla clients con esquema corregido...');
      await query(`
        CREATE TABLE clients (
          id VARCHAR(255) PRIMARY KEY,
          name VARCHAR(255) NOT NULL,
          nit VARCHAR(50),
          address TEXT,
          city VARCHAR(100),
          seller_id VARCHAR(255),
          active BOOLEAN DEFAULT TRUE,
          created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
          updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
      `);
      logger.info('‚úÖ Tabla clients creada con esquema corregido');
      return { created: true, altered: false };
    }
    
    // 2. Verificar y corregir columnas
    logger.info('üìã Verificando estructura de la tabla...');
    const currentColumns = await query(`
      SELECT column_name, data_type, is_nullable
      FROM information_schema.columns
      WHERE table_schema = 'public' 
        AND table_name = 'clients'
      ORDER BY ordinal_position;
    `);
    
    const columnNames = currentColumns.rows.map(row => row.column_name.toLowerCase());
    let alterations = [];
    
    // Primero manejar renames/copies de columnas problem√°ticas
    const hasSellerId = columnNames.includes('seller_id');
    const hasSellerid = columnNames.includes('sellerid');
    const hasSeller = columnNames.includes('seller');
    
    if (hasSellerid && !hasSellerId) {
      // Caso 1: sellerid existe, seller_id no existe ‚Üí renombrar
      logger.info('üîÑ Renombrando columna sellerid ‚Üí seller_id');
      await query(`ALTER TABLE clients RENAME COLUMN sellerid TO seller_id`);
      alterations.push('RENAME sellerid ‚Üí seller_id');
      // Actualizar lista de columnas
      columnNames[columnNames.indexOf('sellerid')] = 'seller_id';
    } else if (hasSellerid && hasSellerId) {
      // Caso 2: ambas columnas existen ‚Üí copiar datos y eliminar sellerid
      logger.info('üìã Copiando datos de sellerid a seller_id...');
      await query(`UPDATE clients SET seller_id = sellerid WHERE seller_id IS NULL AND sellerid IS NOT NULL`);
      logger.info('üóëÔ∏è  Eliminando columna sellerid');
      await query(`ALTER TABLE clients DROP COLUMN sellerid`);
      alterations.push('COPY sellerid ‚Üí seller_id, DROP sellerid');
      // Actualizar lista de columnas
      columnNames.splice(columnNames.indexOf('sellerid'), 1);
    } else if (hasSeller && !hasSellerId && !hasSellerid) {
      // Caso 3: seller existe, seller_id no existe ‚Üí renombrar
      logger.info('üîÑ Renombrando columna seller ‚Üí seller_id');
      await query(`ALTER TABLE clients RENAME COLUMN seller TO seller_id`);
      alterations.push('RENAME seller ‚Üí seller_id');
      // Actualizar lista de columnas
      columnNames[columnNames.indexOf('seller')] = 'seller_id';
    }
    
    // Verificar columnas requeridas (despu√©s de manejar renames)
    const requiredColumns = [
      { name: 'id', type: 'VARCHAR(255)', nullable: 'NO' },
      { name: 'name', type: 'VARCHAR(255)', nullable: 'NO' },
      { name: 'nit', type: 'VARCHAR(50)', nullable: 'YES' },
      { name: 'address', type: 'TEXT', nullable: 'YES' },
      { name: 'city', type: 'VARCHAR(100)', nullable: 'YES' },
      { name: 'seller_id', type: 'VARCHAR(255)', nullable: 'YES' },
      { name: 'active', type: 'BOOLEAN', nullable: 'NO' },
      { name: 'created_at', type: 'TIMESTAMP', nullable: 'YES' },
      { name: 'updated_at', type: 'TIMESTAMP', nullable: 'YES' }
    ];
    
    for (const required of requiredColumns) {
      const exists = columnNames.includes(required.name.toLowerCase());
      
      if (!exists) {
        logger.info(`‚ûï Agregando columna faltante: ${required.name}`);
        await query(`ALTER TABLE clients ADD COLUMN ${required.name} ${required.type} ${required.nullable === 'NO' ? 'NOT NULL' : ''}`);
        alterations.push(`ADD ${required.name}`);
      }
    }
    
    // Convertir active de INTEGER a BOOLEAN si es necesario
    const activeColumn = currentColumns.rows.find(col => col.column_name.toLowerCase() === 'active');
    if (activeColumn && activeColumn.data_type === 'integer') {
      logger.info('üîÑ Convirtiendo active de INTEGER a BOOLEAN');
      // Primero agregar columna temporal
      await query(`ALTER TABLE clients ADD COLUMN active_temp BOOLEAN`);
      // Actualizar valores: 1 ‚Üí true, 0 ‚Üí false, NULL ‚Üí true (default)
      await query(`UPDATE clients SET active_temp = CASE WHEN active = 1 THEN true WHEN active = 0 THEN false ELSE true END`);
      // Eliminar columna original
      await query(`ALTER TABLE clients DROP COLUMN active`);
      // Renombrar temporal a original
      await query(`ALTER TABLE clients RENAME COLUMN active_temp TO active`);
      // Agregar default
      await query(`ALTER TABLE clients ALTER COLUMN active SET DEFAULT true`);
      alterations.push('CONVERT active INTEGER ‚Üí BOOLEAN');
    }
    
    if (alterations.length > 0) {
      logger.info(`‚úÖ Esquema corregido: ${alterations.length} cambios aplicados`);
      return { created: false, altered: true, alterations };
    } else {
      logger.info('‚úÖ Esquema ya est√° correcto');
      return { created: false, altered: false };
    }
    
  } catch (error) {
    logger.error('‚ùå Error preparando esquema:', error);
    throw error;
  }
}

/**
 * Funci√≥n principal de migraci√≥n
 */
async function migrateClientsData() {
  const migrationReport = {
    timestamp: new Date().toISOString(),
    steps: {},
    statistics: {},
    errors: []
  };
  
  try {
    logger.info('üöÄ Iniciando migraci√≥n de datos de clients...\n');
    
    // Paso 0: Inicializar base de datos PostgreSQL
    migrationReport.steps.initPostgres = { start: new Date().toISOString() };
    logger.info('üìä Inicializando conexi√≥n a PostgreSQL...');
    await initDatabase();
    migrationReport.steps.initPostgres.end = new Date().toISOString();
    logger.info('‚úÖ Conexi√≥n a PostgreSQL inicializada');
    
    // Paso 0.5: Preparar esquema de PostgreSQL
    migrationReport.steps.prepareSchema = { start: new Date().toISOString() };
    const schemaResult = await preparePostgresSchema();
    migrationReport.steps.prepareSchema.end = new Date().toISOString();
    migrationReport.steps.prepareSchema.result = schemaResult;
    
    // Paso 1: Leer datos de SQLite
    migrationReport.steps.readSqlite = { start: new Date().toISOString() };
    const sqliteRecords = await readSqliteClients();
    migrationReport.steps.readSqlite.end = new Date().toISOString();
    migrationReport.steps.readSqlite.recordCount = sqliteRecords.length;
    
    // Paso 2: Transformar datos
    migrationReport.steps.transform = { start: new Date().toISOString() };
    const transformedRecords = [];
    const validationErrors = [];
    
    for (const sqliteRecord of sqliteRecords) {
      try {
        const transformed = transformClientRecord(sqliteRecord);
        const validation = validateTransformedRecord(transformed);
        
        if (validation.isValid) {
          transformedRecords.push(transformed);
        } else {
          validationErrors.push({
            id: sqliteRecord.id,
            errors: validation.errors
          });
          logger.warn(`‚ö†Ô∏è  Registro ${sqliteRecord.id} tiene errores: ${validation.errors.join(', ')}`);
        }
      } catch (error) {
        validationErrors.push({
          id: sqliteRecord.id,
          errors: [error.message]
        });
        logger.error(`‚ùå Error transformando registro ${sqliteRecord.id}:`, error);
      }
    }
    
    migrationReport.steps.transform.end = new Date().toISOString();
    migrationReport.steps.transform.transformedCount = transformedRecords.length;
    migrationReport.steps.transform.errorCount = validationErrors.length;
    migrationReport.statistics.validationErrors = validationErrors;
    
    if (validationErrors.length > 0) {
      logger.warn(`‚ö†Ô∏è  ${validationErrors.length} registros tienen errores de validaci√≥n`);
    }
    
    // Paso 3: Insertar datos en PostgreSQL (por lotes)
    migrationReport.steps.insert = { start: new Date().toISOString() };
    const batches = [];
    const batchCount = Math.ceil(transformedRecords.length / MIGRATION_CONFIG.batchSize);
    
    logger.info(`üì¶ Procesando ${transformedRecords.length} registros en ${batchCount} lotes...`);
    
    let totalInserted = 0;
    let batchErrors = [];
    
    for (let i = 0; i < batchCount; i++) {
      const start = i * MIGRATION_CONFIG.batchSize;
      const end = start + MIGRATION_CONFIG.batchSize;
      const batch = transformedRecords.slice(start, end);
      const batchNumber = i + 1;
      
      let retryCount = 0;
      let batchSuccess = false;
      
      while (retryCount < MIGRATION_CONFIG.maxRetries && !batchSuccess) {
        try {
          if (retryCount > 0) {
            logger.warn(`üîÑ Reintentando lote ${batchNumber} (intento ${retryCount + 1})...`);
            await new Promise(resolve => setTimeout(resolve, MIGRATION_CONFIG.retryDelay));
          }
          
          const inserted = await insertBatchToPostgres(batch, batchNumber);
          totalInserted += inserted;
          batchSuccess = true;
          batches.push({ batchNumber, success: true, recordCount: batch.length });
          
        } catch (error) {
          retryCount++;
          if (retryCount === MIGRATION_CONFIG.maxRetries) {
            logger.error(`‚ùå Lote ${batchNumber} fall√≥ despu√©s de ${MIGRATION_CONFIG.maxRetries} intentos:`, error);
            batchErrors.push({
              batchNumber,
              error: error.message,
              recordCount: batch.length
            });
            batches.push({ batchNumber, success: false, error: error.message });
          }
        }
      }
    }
    
    migrationReport.steps.insert.end = new Date().toISOString();
    migrationReport.steps.insert.batchCount = batches.length;
    migrationReport.steps.insert.successfulBatches = batches.filter(b => b.success).length;
    migrationReport.steps.insert.failedBatches = batches.filter(b => !b.success).length;
    migrationReport.steps.insert.totalInserted = totalInserted;
    migrationReport.statistics.batchErrors = batchErrors;
    
    if (batchErrors.length > 0) {
      logger.error(`‚ùå ${batchErrors.length} lotes fallaron durante la inserci√≥n`);
    }
    
    // Paso 4: Validar migraci√≥n
    migrationReport.steps.validate = { start: new Date().toISOString() };
    const validationResult = await validateMigration();
    migrationReport.steps.validate.end = new Date().toISOString();
    migrationReport.steps.validate.result = validationResult;
    
    // Generar reporte
    console.log('\n' + '='.repeat(80));
    console.log('üìã REPORTE DE MIGRACI√ìN - TABLA CLIENTS');
    console.log('='.repeat(80));
    console.log(`üìÖ Fecha: ${migrationReport.timestamp}`);
    console.log(`üöÄ Estado: ${batchErrors.length === 0 ? '‚úÖ COMPLETADO' : '‚ö†Ô∏è  CON ERRORES'}`);
    
    console.log('\n' + '-'.repeat(80));
    console.log('üìä ESTAD√çSTICAS:');
    console.log(`‚Ä¢ Registros en SQLite: ${sqliteRecords.length}`);
    console.log(`‚Ä¢ Registros transformados: ${transformedRecords.length}`);
    console.log(`‚Ä¢ Errores de validaci√≥n: ${validationErrors.length}`);
    console.log(`‚Ä¢ Lotes procesados: ${batches.length}`);
    console.log(`‚Ä¢ Lotes exitosos: ${batches.filter(b => b.success).length}`);
    console.log(`‚Ä¢ Lotes fallidos: ${batches.filter(b => !b.success).length}`);
    console.log(`‚Ä¢ Registros insertados: ${totalInserted}`);
    
    if (validationResult.matches) {
      console.log(`‚Ä¢ Validaci√≥n: ‚úÖ Los conteos coinciden (${validationResult.sqliteCount} registros)`);
    } else {
      console.log(`‚Ä¢ Validaci√≥n: ‚ùå Los conteos NO coinciden`);
    }
    
    if (validationErrors.length > 0) {
      console.log('\n' + '‚ö†Ô∏è  ERRORES DE VALIDACI√ìN:');
      validationErrors.slice(0, 5).forEach(error => {
        console.log(`  ‚Ä¢ ${error.id}: ${error.errors.join(', ')}`);
      });
      if (validationErrors.length > 5) {
        console.log(`  ... y ${validationErrors.length - 5} m√°s`);
      }
    }
    
    if (batchErrors.length > 0) {
      console.log('\n' + '‚ùå ERRORES EN LOTES:');
      batchErrors.forEach(error => {
        console.log(`  ‚Ä¢ Lote ${error.batchNumber}: ${error.error}`);
      });
    }
    
    console.log('\n' + '-'.repeat(80));
    console.log('‚è±Ô∏è  TIEMPOS DE EJECUCI√ìN:');
    const steps = migrationReport.steps;
    const stepOrder = ['initPostgres', 'prepareSchema', 'readSqlite', 'transform', 'insert', 'validate'];
    for (const stepName of stepOrder) {
      const stepData = steps[stepName];
      if (stepData && stepData.start && stepData.end) {
        const start = new Date(stepData.start);
        const end = new Date(stepData.end);
        const duration = (end - start) / 1000;
        const stepDisplayName = {
          initPostgres: 'Inicializar PostgreSQL',
          prepareSchema: 'Preparar esquema',
          readSqlite: 'Leer SQLite',
          transform: 'Transformar datos',
          insert: 'Insertar en PostgreSQL',
          validate: 'Validar migraci√≥n'
        }[stepName] || stepName;
        console.log(`‚Ä¢ ${stepDisplayName}: ${duration.toFixed(2)}s`);
      }
    }
    
    console.log('\n' + '='.repeat(80));
    
    if (batchErrors.length > 0) {
      console.log('‚ùå La migraci√≥n complet√≥ con errores. Revise el reporte anterior.');
      process.exit(1);
    } else {
      console.log('‚úÖ Migraci√≥n completada exitosamente!');
      console.log('‚úÖ Los datos de clients han sido migrados de SQLite a PostgreSQL.');
      console.log('‚úÖ Puede proceder con las siguientes tareas del plan de implementaci√≥n.');
    }
    
    return migrationReport;
    
  } catch (error) {
    logger.error('‚ùå Error fatal durante la migraci√≥n:', error);
    console.error('\n‚ùå MIGRACI√ìN FALLIDA:', error.message);
    console.error('‚ùå Revise los logs para m√°s detalles.');
    process.exit(1);
  }
}

// Si se ejecuta directamente
if (require.main === module) {
  migrateClientsData()
    .then(report => {
      if (report.statistics.batchErrors && report.statistics.batchErrors.length > 0) {
        process.exit(1);
      } else {
        process.exit(0);
      }
    })
    .catch(error => {
      console.error('‚ùå Error fatal:', error);
      process.exit(1);
    });
}

module.exports = {
  migrateClientsData,
  transformClientRecord,
  validateTransformedRecord,
  readSqliteClients,
  insertBatchToPostgres,
  validateMigration
};